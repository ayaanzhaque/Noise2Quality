{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "iqam_analysis.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAwwq66tNtTO"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffu8BU-ZbJmK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hri8KDtaA-W"
      },
      "source": [
        "!pip install dicom_numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l25Yh_uJb0nA"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "from scipy import signal\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "from skimage.transform import resize\n",
        "import pdb\n",
        "\n",
        "import pydicom as dicom\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from glob import glob\n",
        "# import SimpleITK as sitk\n",
        "import dicom_numpy as dcm2np\n",
        "import os, re\n",
        "from skimage.transform import resize\n",
        "import argparse\n",
        "from scipy.io import savemat\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "from scipy import ndimage\n",
        "\n",
        "#Using hd5\n",
        "import h5py\n",
        "\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import h5py\n",
        "from scipy.io import loadmat\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import gc, copy\n",
        "from collections import defaultdict\n",
        "from torchsummary import summary\n",
        "\n",
        "import nibabel as nib\n",
        "from scipy.ndimage import rotate\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import sys, h5py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjIC4u8a30CJ"
      },
      "source": [
        "def show_img(img, cmap = 'gray'):\n",
        "  if img.shape == (256, 256):\n",
        "    plt.imshow(img, cmap = cmap)\n",
        "  elif img.shape == (1, 256, 256):\n",
        "    plt.imshow(np.squeeze(img), cmap = cmap)\n",
        "  else:\n",
        "    print(\"bad shape\")\n",
        "\n",
        "  plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e1k8_v2x46j"
      },
      "source": [
        "def make_figure(img, cmap = 'gray'):\n",
        "  if img.shape == (256, 256):\n",
        "    plt.imshow(img, cmap = cmap)\n",
        "  elif img.shape == (1, 256, 256):\n",
        "    plt.imshow(np.squeeze(img), cmap = cmap)\n",
        "  else:\n",
        "    print(\"bad shape\")\n",
        "\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLHBm0XT_ZSZ"
      },
      "source": [
        "# SSIM Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ADOxyCs_YL5"
      },
      "source": [
        "def calc_ssim(img1, img2):\n",
        "    \n",
        "    K = [0.01, 0.03]\n",
        "    L = 1\n",
        "    kernelX = cv2.getGaussianKernel(11, 1.5)\n",
        "    window = kernelX * kernelX.T\n",
        "     \n",
        "    M,N = np.shape(img1)\n",
        "\n",
        "    C1 = (K[0]*L)**2\n",
        "    C2 = (K[1]*L)**2\n",
        "    img1 = np.float64(img1)\n",
        "    img2 = np.float64(img2)\n",
        " \n",
        "    mu1 = signal.convolve2d(img1, window, 'valid')\n",
        "    mu2 = signal.convolve2d(img2, window, 'valid')\n",
        "    \n",
        "    mu1_sq = mu1*mu1\n",
        "    mu2_sq = mu2*mu2\n",
        "    mu1_mu2 = mu1*mu2\n",
        "    \n",
        "    \n",
        "    sigma1_sq = signal.convolve2d(img1*img1, window, 'valid') - mu1_sq\n",
        "    sigma2_sq = signal.convolve2d(img2*img2, window, 'valid') - mu2_sq\n",
        "    sigma12 = signal.convolve2d(img1*img2, window, 'valid') - mu1_mu2\n",
        "   \n",
        "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    ssim_map = resize(ssim_map, img1.shape)\n",
        "\n",
        "    mssim = np.mean(ssim_map)\n",
        "    return ssim_map, mssim\n",
        "\n",
        "#Gets all the image slices for a CT scan and returns slice-wise scores\n",
        "def get_SSIM(fd_images, ld_images):\n",
        "    assert fd_images.ndim == 3\n",
        "    assert ld_images.ndim == 3\n",
        "    \n",
        "    ssim_scores, maps = [], []\n",
        "    \n",
        "    #print(ld_images.shape)\n",
        "    \n",
        "    for idx in range(ld_images.shape[0]):\n",
        "        #print(idx)\n",
        "        img1 = fd_images[idx]\n",
        "        img2 = ld_images[idx]\n",
        "        \n",
        "        '''Calculate the SSIM score'''\n",
        "        map, score = calc_ssim(img1, img2)\n",
        "        \n",
        "        #print(score, gscore)\n",
        "        ssim_scores.append(score)\n",
        "        maps.append(map)\n",
        "\n",
        "    return maps, ssim_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpV4w7MC_QiM"
      },
      "source": [
        "# Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yf4mHT4_TUg"
      },
      "source": [
        "def sort_dicom(pathdir):\n",
        "    #pathdir = './LDCT/'\n",
        "    fd_folds, ld_folds = [], []\n",
        "\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        for dir in dirs:\n",
        "            fold = os.path.join(root,dir+'/')\n",
        "            if re.search(\"Full\", fold):\n",
        "                fd_folds.append(fold)\n",
        "            if re.search(\"Low\", fold+'/'):\n",
        "                ld_folds.append(fold)\n",
        "            \n",
        "    assert len(fd_folds) == len(ld_folds)\n",
        "    \n",
        "    #sort the list of dicom files\n",
        "    fd_folds.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
        "    ld_folds.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
        "\n",
        "    return fd_folds, ld_folds\n",
        "#Returns numpy array and image affine from a list of dicoms\n",
        "def extract_voxel_data(dicom_dir):\n",
        "    nd_data = np.zeros((0, 512, 512))\n",
        "    \n",
        "    for dcm_dir in dicom_dir:\n",
        "        dcm_files = glob(dcm_dir+'*.dcm')\n",
        "        dcm_files.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[0-9]|[0-9]+', var)])\n",
        "\n",
        "        datasets = [dicom.read_file(f) for f in dcm_files]\n",
        "        nd_array, afn = dcm2np.combine_slices(datasets)\n",
        "    \n",
        "        nd_array = nd_array.transpose(2, 1, 0)\n",
        "        nd_data = np.concatenate([nd_data, nd_array], axis=0)\n",
        "    \n",
        "    return nd_data \n",
        "def window_level(x, w, c, ymin=0, ymax=1.):\n",
        "    sh = x.shape\n",
        "\n",
        "    y = np.zeros(sh) #window-leveled image\n",
        "    \n",
        "    #print(x[x >= -110 & x < 189])\n",
        "    #if (x <= c - 0.5 - (w-1) /2), then y = ymin\n",
        "    mask1 = ( x <= (c - 0.5 - (w-1) /2) )\n",
        "    y[mask1] = ymin #Update\n",
        "    \n",
        "    #else if (x > c - 0.5 + (w-1) /2), then y = ymax\n",
        "    mask2 = ( x > (c - 0.5 + (w-1) /2) )\n",
        "    y[mask2] = ymax #Update\n",
        "\n",
        "    #else y = ((x - (c - 0.5)) / (w-1) + 0.5) * (ymax- ymin) + ymin\n",
        "    mask3 = ( x > (c - 0.5 - (w-1) /2)) & (x <= (c - 0.5 + (w-1) /2) ) \n",
        "    np.putmask(y, mask3, ((x - (c - 0.5)) / (w-1) + 0.5) * (ymax- ymin) + ymin) #Update\n",
        "    \n",
        "    return y #return window-leveled image\n",
        "def prep_slices(volume, scale=256):\n",
        "    resized_data = []\n",
        "    \n",
        "    for i in range(volume.shape[0]):\n",
        "        '''abdomen: window width=300, center=40'''\n",
        "        img = window_level(volume[i], 300, 40)\n",
        "        #print('Img max-min: ', np.max(img), np.min(img))\n",
        "        \n",
        "        img = resize(img, [scale, scale])\n",
        "        assert img.shape == (scale, scale)\n",
        "        try:\n",
        "            assert np.max(img) == 1.\n",
        "            assert np.min(img) == 0.\n",
        "        except:\n",
        "            pass\n",
        "        resized_data.append(img)\n",
        "    \n",
        "    resized_data = np.reshape(resized_data, [-1, scale, scale])\n",
        "\n",
        "    return resized_data\n",
        "#Simulate low-dose\n",
        "'''\n",
        "Given: quarter dose and full dose CT images, required Dose level.\n",
        "Return: Images at the Dose level\n",
        "'''\n",
        "def simulate_ld(I_qd, I_fd, Dose=1.):\n",
        "    if Dose==1:\n",
        "        return I_fd\n",
        "    elif Dose==0.25:\n",
        "        return I_qd\n",
        "    else:\n",
        "        a = np.sqrt(((1/Dose)-1)/3)\n",
        "        print(a)\n",
        "\n",
        "        I_noise = I_qd - I_fd\n",
        "\n",
        "        return I_fd+(a*I_noise)\n",
        "#normalize input images: high pass filtering\n",
        "def normalize_image(img):\n",
        "    gblurr = cv2.GaussianBlur(img,(5,5), cv2.BORDER_DEFAULT) #gaussian blurr\n",
        "    ds = ndimage.interpolation.zoom(gblurr,.5) #downsample by 2\n",
        "    I_bar = ndimage.interpolation.zoom(ds, 2) #upsample by 2\n",
        "\n",
        "    I_norm =  img - I_bar #normalized image obtained after high-pass filtering\n",
        "\n",
        "    return I_norm\n",
        "def prepare_error(ld_data, fd_data, h=256, w=256):\n",
        "    '''\n",
        "    Noisy input: High Pass Filtering\n",
        "    I_norm = I - I_bar: I_bar = UpSample(DownSample2(Gauss_Blur(I)))\n",
        "    '''\n",
        "\n",
        "    input_norm = []\n",
        "    error_map = []\n",
        "    labels = []\n",
        "\n",
        "    for i in range(ld_data.shape[0]):\n",
        "        img = ld_data[i]\n",
        "        E = np.abs(fd_data[i]-ld_data[i]) #Error-map obtained frp, the difference of fd and ld images\n",
        "        error_map.append(E)\n",
        "\n",
        "    error_map = np.reshape(error_map, [-1, h, w])  \n",
        "\n",
        "    return error_map\n",
        "\n",
        "def prepare_dose_labels(length, dose):\n",
        "  return np.full((length), dose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbywGkD4BUcr"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz3q5TAjBZHo"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "  def __init__(self, x, m, d, transform=None):\n",
        "    self.images = x\n",
        "    self.maps = m\n",
        "    self.doses = d\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    images = self.images[idx]\n",
        "    maps = self.maps[idx]\n",
        "    doses = self.doses[idx]\n",
        "\n",
        "    if self.transform:\n",
        "      images = self.transform(images)\n",
        "      maps = self.transform(maps)\n",
        "\n",
        "    return [images, maps, doses]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKy5bWyVBbfD"
      },
      "source": [
        "# use the same transformations for train/val in this example\n",
        "trans = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5,), (0.5,)) # imagenet\n",
        "])\n",
        "\n",
        "#Load train data\n",
        "def train_DataLoader(data_filename, batch_size):\n",
        "\n",
        "    with h5py.File(data_filename, 'r') as f:\n",
        "        images = f['Images'][()]\n",
        "        maps = f['I_maps'][()]\n",
        "        doses = f['Dose_labels'][()].astype('float')#.reshape(-1) \n",
        " \n",
        "    print('Images: ', images.shape, 'Maps: ', maps.shape, 'Doses: ', doses.shape)\n",
        "   \n",
        "    indices = np.arange(images.shape[0]) #input indices\n",
        "\n",
        "    #x_train-->input images, y_train-->Quality map, s_train-->gscores, d_train-->Error map\n",
        "\n",
        "    x_train, x_val, y_train, y_val, idx_train, idx_val = train_test_split(images, maps, indices, test_size=0.05, random_state=40)###\n",
        "\n",
        "    d_val = doses[idx_val]\n",
        "    d_train = doses[idx_train]\n",
        "    \n",
        "    train_set = Dataset(x_train, y_train, d_train, transform = trans)\n",
        "    val_set = Dataset(x_val, y_val, d_val, transform = trans)\n",
        "\n",
        "    train_loader = {\n",
        "        'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
        "        'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    }\n",
        "\n",
        "    return train_loader\n",
        "\n",
        "#Load test data\n",
        "def test_DataLoader(data_filename, batch_size, norm=True):\n",
        "    print('Data from ', data_filename)\n",
        "    try:\n",
        "        with h5py.File(data_filename, 'r') as f:\n",
        "          images = f['Images'][()]\n",
        "          maps = f['I_maps'][()]\n",
        "          doses = f['Dose_labels'][()].astype('float').reshape(-1) \n",
        "    except:\n",
        "        print('test data not found......')\n",
        "\n",
        "    print('Images: ', images.shape, 'Maps: ', maps.shape, 'Doses: ', doses.shape)\n",
        "    test_set = Dataset(images, maps, doses, transform=trans)\n",
        "\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    return test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7QaFlVdCcG-"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxF6qNu3Eii1"
      },
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal(m.weight, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        torch.nn.init.normal(m.weight, 1.0, 0.02)\n",
        "        torch.nn.init.constant(m.bias, 0.0)\n",
        "\n",
        "\n",
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.InstanceNorm2d(out_channels),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.InstanceNorm2d(in_channels),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout(0.25)\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ4bJLKBEmgr"
      },
      "source": [
        "class SSPWAM(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.dconv_down1 = double_conv(1, 16)\n",
        "        self.dconv_down2 = double_conv(16, 32)\n",
        "        self.dconv_down3 = double_conv(32, 64)\n",
        "        self.dconv_down4 = double_conv(64, 128)\n",
        "        self.dconv_down5 = double_conv(128, 256)\n",
        "\n",
        "        # classification branch   \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))       \n",
        "        self.fc = nn.Linear(256, 5)\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
        "        \n",
        "        self.dconv_up4 = double_conv(256 + 128, 128)\n",
        "        self.dconv_up3 = double_conv(128 + 64, 64)\n",
        "        self.dconv_up2 = double_conv(64 + 32, 32)\n",
        "        self.dconv_up1 = double_conv(32 + 16, 16)\n",
        "        \n",
        "        self.conv_last = nn.Conv2d(16, 1, 1)\n",
        "        self.tanh = nn.Tanh() # testing with tanh\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_down1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_down2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "        \n",
        "        conv3 = self.dconv_down3(x)\n",
        "        x = self.maxpool(conv3)   \n",
        "\n",
        "        conv4 = self.dconv_down4(x)\n",
        "        x = self.maxpool(conv4)\n",
        "\n",
        "        x = self.dconv_down5(x)\n",
        "        x1 = self.maxpool(x)\n",
        "        \n",
        "        # classification branch\n",
        "        avgpool = self.avgpool(x1)\n",
        "        avgpool = avgpool.view(avgpool.size(0), -1)\n",
        "        outC = self.fc(avgpool)\n",
        "\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv4], dim=1)\n",
        "\n",
        "        x = self.dconv_up4(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv3], dim=1)       \n",
        "\n",
        "        x = self.dconv_up3(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv2], dim=1)       \n",
        "\n",
        "        x = self.dconv_up2(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv1], dim=1) \n",
        "        \n",
        "        x = self.dconv_up1(x)\n",
        "        out = self.conv_last(x)\n",
        "\n",
        "        out = self.tanh(out)\n",
        "        \n",
        "        return out, outC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDEG-6nW6ldx"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGHelRDBC0jo"
      },
      "source": [
        "scan = \"abdomen\"\n",
        "model = \"iqam\"\n",
        "n_epochs = 15\n",
        "batch_size = 16\n",
        "lr = 0.0002\n",
        "img_size = 256\n",
        "\n",
        "C,H,W = channels, img_size, img_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e80Dk_uVETX0"
      },
      "source": [
        "save_path = model + '/' + scan + '/'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "train_path = '/content/drive/MyDrive/Research/QualityMap_Ayaan/data/abdomen/train/ssim_data_train_dose_final.hdf5'\n",
        "test_path = '/content/drive/MyDrive/Research/QualityMap_Ayaan/data/abdomen/test/ssim_data_test_dose_final.hdf5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl-qLjG9Evw2"
      },
      "source": [
        "def train(model, dataloader, criterion, optimizer, scheduler, epochs, save_path, alpha = 1.0):\n",
        "  #Training\n",
        "  torch.autograd.set_detect_anomaly(True)\n",
        "  best_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss = 1e10\n",
        "  start_time = time.time()\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      print('Epoch: ', epoch,'...')\n",
        "      for phase in ['train', 'val']:\n",
        "          if phase == 'train':\n",
        "              model.train()\n",
        "          else:\n",
        "              model.eval()\n",
        "        \n",
        "          \n",
        "          dose_losses, map_losses = 0.0, 0.0\n",
        "\n",
        "          for i, (imgs, maps, dose_labels) in enumerate(dataloader[phase]):\n",
        "              gc.collect()\n",
        "              torch.cuda.empty_cache()\n",
        "              \n",
        "              # Configure input\n",
        "              batch_imgs = Variable(imgs.type(Tensor))\n",
        "              batch_maps = Variable(maps.type(Tensor)) # GSSIM Maps\n",
        "              dose_labels = Variable(dose_labels.type(Tensor))\n",
        "\n",
        "              # batch_imgs = batch_imgs.to(device=device, dtype=torch.float)\n",
        "              # batch_maps = batch_maps.to(device=device, dtype=torch.float)\n",
        "              dose_labels = dose_labels.to(device=device, dtype=torch.long)\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              with torch.set_grad_enabled(phase == 'train'): \n",
        "                  # ---------------------\n",
        "                  #  Train U-Net\n",
        "                  # ---------------------\n",
        "\n",
        "                  # Get outputs\n",
        "                  pred_maps, pred_dose = model(batch_imgs)\n",
        "\n",
        "                  dose_labels = torch.argmax(dose_labels, 1)\n",
        "\n",
        "                  # Map loss\n",
        "                  map_loss = torch.mean(torch.abs(batch_maps - pred_maps))\n",
        "                  # Dose Loss\n",
        "                  dose_loss = criterion(pred_dose, dose_labels)\n",
        "\n",
        "                  # Total Loss\n",
        "\n",
        "                  loss = map_loss + alpha * dose_loss\n",
        "\n",
        "                  if phase == 'train':\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "\n",
        "              \n",
        "              #Collect losses    \n",
        "              dose_losses += float(dose_loss)*imgs.size(0)\n",
        "              map_losses += float(map_loss)*imgs.size(0)\n",
        "\n",
        "              if i % 10 == 0:\n",
        "                print(\"STEP\" + str(i))\n",
        "\n",
        "          print(phase, \": [Batch %d/%d] [Total loss: %f] [Map loss: %f] [Dose loss: %f]\" % (i, len(dataloader[phase]), loss.data.cpu(), map_loss.data.cpu(), dose_loss.data.cpu())) \n",
        "\n",
        "          epoch_loss = (loss/len(dataloader[phase]))\n",
        "\n",
        "          if phase == 'train':\n",
        "              scheduler.step()\n",
        "\n",
        "          if phase == 'val':\n",
        "              if epoch_loss < best_loss:\n",
        "                  print(\"saving best model...\")\n",
        "                  best_loss = epoch_loss\n",
        "                  best_wts = copy.deepcopy(model.state_dict())\n",
        "                  torch.save(best_wts, save_path + f'.pth')\n",
        "                  print('Model saved at epoch: ', epoch)\n",
        "\n",
        "  model.load_state_dict(torch.load(save_path + f'.pth'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRm10LuuEuC-"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Loss function\n",
        "criterion = torch.nn.CrossEntropyLoss() #torch.nn.BCELoss()\n",
        "\n",
        "# Initialize models\n",
        "model = UNet()\n",
        "\n",
        "# Optimizers\n",
        "\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=1.) #for step-wise leaning rate scheduler\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "alpha = 0.01\n",
        "\n",
        "save_path = \"model\"\n",
        "\n",
        "if cuda: \n",
        "    model.cuda()\n",
        "    criterion.cuda()\n",
        "\n",
        "print('Model: ', summary(model, input_size=(1, 256, 256)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVNOpeN5Ep0O"
      },
      "source": [
        "train_dataloader = train_DataLoader(train_path, batch_size)\n",
        "\n",
        "print('the data is ok')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3_6btNv932I"
      },
      "source": [
        "gc.collect()\n",
        "# train(model, dataloader, criterion, optimizer, scheduler, epochs, save_path, alpha)\n",
        "model = train(model, train_dataloader, criterion, optimizer, scheduler, n_epochs, save_path, alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49ox9-I9oXiZ"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(save_path + \".pth\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}